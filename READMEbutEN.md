# ğŸ“Š LinkedIn Job Application Tracker

A platform that automatically fetches and analyzes your LinkedIn job applications.

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.40+-red.svg)
![n8n](https://img.shields.io/badge/n8n-Automation-orange.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

---

## ğŸ”„ Part 1: n8n Automation

The n8n workflow automatically fetches LinkedIn application emails from Gmail, categorizes them, and saves them to Google Sheets.

### ğŸ“‹ Workflow Structure

```
Manual Trigger â†’ Gmail â†’ Categorize & Extract Data â†’ Filter â†’ Google Sheets
```

### ğŸ”§ Workflow Nodes

| Node | Description |
|------|-------------|
| **Manual Trigger** | Manually starts the workflow |
| **Gmail** | Fetches emails from LinkedIn (linkedin.com sender filter) |
| **Categorize & Extract Data** | Analyzes emails, extracts company/position/status info |
| **Filter** | Filters only job application emails |
| **Google Sheets** | Saves data to Google Sheets |

### ğŸ“§ Email Categories

The workflow categorizes emails into the following:

| Category | Status | Trigger Keywords |
|----------|--------|-----------------|
| `application_submitted` | Applied | "application was sent", "your application to" |
| `application_viewed` | Under Review | "application was viewed" |
| `interview_invite` | Interview | "interview" |
| `rejected` | Rejected | "unfortunately", "not moving forward" |

### âš™ï¸ n8n Setup

1. Create an [n8n](https://n8n.io/) account (cloud or self-hosted)
2. Import the `applications.json` file into n8n
3. Configure credentials:

#### Gmail OAuth2 Credential
```
1. Create OAuth 2.0 credential in Google Cloud Console
2. Enable Gmail API
3. Add Gmail OAuth2 credential in n8n
4. Update YOUR_GMAIL_CREDENTIAL_ID and YOUR_GMAIL_CREDENTIAL_NAME in the workflow
```

#### Google Sheets OAuth2 Credential
```
1. Create OAuth 2.0 credential in Google Cloud Console
2. Enable Google Sheets API
3. Add Google Sheets OAuth2 credential in n8n
4. Update YOUR_GOOGLE_SHEETS_CREDENTIAL_ID and YOUR_GOOGLE_SHEETS_CREDENTIAL_NAME in the workflow
```

4. Update your Google Sheets URL:
   - `YOUR_GOOGLE_SHEETS_URL` â†’ Your own Google Sheets link

### ğŸ“Š Google Sheets Columns

The workflow creates these columns:

| Column | Description |
|--------|-------------|
| Date | Application date |
| Time | Application time |
| Company | Company name |
| Position | Position title |
| Category | Category code |
| Status | Status |
| Subject | Email subject |
| Gmail Link | Direct link to email in Gmail |
| Processed At | Processing timestamp |

### â–¶ï¸ Running the Workflow

1. Open the workflow in n8n
2. Click "Execute Workflow" button
3. Emails are fetched from Gmail and processed
4. Data is saved to Google Sheets
5. Export as CSV from Google Sheets

---

## ğŸ“ˆ Part 2: Streamlit Dashboard

The Streamlit dashboard visualizes and analyzes data from n8n.

### ğŸ¯ Features

- **Metric Cards**: Total applications, interviews, rejection rate
- **Status Distribution**: Pie chart visualization
- **Time Trend**: Daily application chart + 7-day moving average
- **Company Analysis**: Most applied companies
- **Position Analysis**: Popular positions
- **Weekly/Monthly Histogram**: Periodic activity
- **Response Funnel**: Application â†’ View â†’ Interview flow
- **Filtering**: Date, status, company-based filtering
- **HTML Export**: Download all analyses in one file

### ğŸš€ Installation

```bash
# Install dependencies
pip install -r requirements.txt

# Run the application
streamlit run app.py
```

### ğŸ“‹ Usage

1. **CSV Upload**: Upload your CSV from n8n via the left panel
2. **Demo Mode**: "Use demo data" option to test without CSV
3. **Filtering**: Date range, status, and company filters
4. **Export**: Download as CSV or HTML dashboard

### ğŸ¨ Dashboard Sections

#### Overview
- Total application count
- Unique company count
- Interview invitation count
- Under review count
- Rejection rate

#### Detailed Analytics
- Application status distribution (pie chart)
- Application response funnel
- Daily application trend
- Most applied companies (bar chart)
- Most applied positions
- Weekly/Monthly histogram (selectable)
- Company-based status distribution

#### Application Details
- Table view (first 50 records)
- Direct email access via Gmail link

### ğŸ“Š Data Format

The dashboard expects this CSV format:

```csv
Date,Company,Position,Category,Status,Subject,Gmail Link,Processed At
2025-01-15,Company A,Position 1,application_submitted,Applied,Your application...,https://mail...,2025-01-15T10:30:00.000Z
```

### ğŸ–¥ï¸ HTML Dashboard Export

Download an interactive HTML file containing all analyses with the "Download Dashboard" button:
- All charts (Plotly interactive)
- Metric cards
- Detailed table
- Print-friendly design

---

## ğŸ“ Project Structure

```
linkedin_basvurular/
â”œâ”€â”€ app.py              # Streamlit dashboard application
â”œâ”€â”€ applications.json   # n8n workflow file
â”œâ”€â”€ sample_data.csv     # Sample dataset (anonymous)
â”œâ”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ .gitignore          # Git ignore file
â”œâ”€â”€ README.md           # Turkish documentation
â””â”€â”€ READMEbutEN.md      # English documentation (this file)
```

---

## ğŸ” Security Notes

- Credential IDs in `applications.json` are placeholder values
- Do not upload your real application data to GitHub
- `.gitignore` automatically ignores sensitive data
- `sample_data.csv` is completely anonymous sample data

---

## ğŸ¤ Contributing

1. Fork this repo
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push your branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License.

---

## ğŸ™ Technologies

- [n8n](https://n8n.io/) - Workflow automation platform
- [Streamlit](https://streamlit.io/) - Python dashboard framework
- [Plotly](https://plotly.com/) - Interactive charts
- [Pandas](https://pandas.pydata.org/) - Data analysis

---

â­ Don't forget to star this project if you found it useful!

